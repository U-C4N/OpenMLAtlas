# 03 - Classical Algorithms

## Overview

This module covers traditional machine learning methods that remain powerful and widely used in industry. You'll learn tree-based models, support vector machines, clustering algorithms, dimensionality reduction techniques, and ensemble methods. These algorithms are interpretable, efficient, and often outperform deep learning on structured/tabular data.

## Learning Path (Folder Order)

Master classical algorithms in this sequence:

1. **tree-based-models/** - Decision trees and their powerful extensions
   - decision-trees/ - Understanding tree construction and splitting criteria
   - random-forest/ - Ensemble of trees with bagging
   - gradient-boosting/ - Sequential tree building with gradient descent
   - xgboost-lightgbm-catboost/ - State-of-the-art gradient boosting implementations

2. **svm/** - Support Vector Machines: maximum margin classifiers and kernel trick

3. **ensemble-methods/** - Combining multiple models for better performance
   - bagging/ - Bootstrap aggregating for variance reduction
   - boosting/ - Sequential learning for bias reduction
   - stacking/ - Meta-learning with multiple model layers

4. **clustering/** - Unsupervised learning for grouping similar data points
   - kmeans/ - Centroid-based clustering algorithm
   - hierarchical-clustering/ - Tree-based clustering with dendrograms
   - dbscan/ - Density-based clustering for arbitrary shapes
   - gmm/ - Gaussian Mixture Models for probabilistic clustering

5. **dimensionality-reduction/** - Reducing feature space while preserving information
   - pca/ - Principal Component Analysis for linear dimensionality reduction
   - lda/ - Linear Discriminant Analysis for supervised dimensionality reduction
   - manifold-learning-tsne-umap/ - Non-linear techniques for visualization

## Resources

### üìö Books

- **"The Elements of Statistical Learning"** by Hastie, Tibshirani, Friedman - Comprehensive classical ML theory
- **"Introduction to Algorithms"** (CLRS) - Algorithm fundamentals including trees and clustering
- **"Pattern Classification"** by Duda, Hart, Stork - Classic pattern recognition text
- **"Data Mining: Practical Machine Learning Tools"** by Witten et al. - Practical classical ML
- **"Learning with Kernels"** by Sch√∂lkopf and Smola - Deep dive into SVMs and kernel methods
- **"Ensemble Methods: Foundations and Algorithms"** by Zhou - Comprehensive ensemble learning guide

### üé• Videos

- **StatQuest: Decision Trees and Random Forests** - Crystal clear explanations
- **StatQuest: XGBoost Series** - Detailed gradient boosting tutorials
- **MIT 6.036: Support Vector Machines** - Mathematical foundations of SVMs
- **Victor Lavrenko: Clustering Lectures** - University-level clustering content
- **Computerphile: Dimensionality Reduction** - Visual PCA explanations
- **Josh Starmer: PCA Clearly Explained** - Step-by-step PCA walkthrough
- **Kaggle Courses: Intermediate ML** - Practical XGBoost and feature importance

### üéß Podcasts

- **Data Skeptic: Episodes on Random Forests and SVMs** - Theoretical foundations
- **TWiML&AI: Gradient Boosting Deep Dives** - Industry applications
- **Linear Digressions: Clustering Episodes** - Accessible algorithm explanations
- **Talking Machines** - ML algorithm discussions
- **Super Data Science Podcast** - Practical ML applications
- **O'Reilly Data Show** - Industry perspectives on classical ML

### üìÑ Articles & Papers

- **"Random Forests"** by Leo Breiman (2001) - Original Random Forest paper
- **"XGBoost: A Scalable Tree Boosting System"** by Chen and Guestrin - XGBoost paper
- **"LightGBM: A Highly Efficient Gradient Boosting Decision Tree"** - Microsoft's LightGBM
- **"CatBoost: Unbiased Boosting with Categorical Features"** - Yandex's CatBoost
- **"A Tutorial on Support Vector Machines"** by Burges - Classic SVM tutorial
- **"k-means++: The Advantages of Careful Seeding"** - Improved k-means initialization
- **"A Tutorial on Principal Component Analysis"** by Jonathon Shlens - Clear PCA explanation
- **"How UMAP Works"** - Understanding UMAP visualization

### üåê HTML/Interactive Resources

- **MLU-Explain: Decision Trees** (mlu-explain.github.io) - Interactive tree visualization
- **Visual Introduction to Decision Trees** (r2d3.us) - Stunning visual tutorial
- **SVM Visualization** (cs.stanford.edu) - Interactive SVM kernel demonstrations
- **K-Means Clustering Visualizer** - Step-by-step centroid updates
- **PCA Explained Visually** (setosa.io/ev/principal-component-analysis) - Interactive PCA
- **t-SNE Playground** - Experiment with t-SNE parameters
- **UMAP Examples** (umap-learn.readthedocs.io) - Interactive UMAP demonstrations
- **Scikit-learn Examples Gallery** - Runnable classical algorithm examples
- **OpenML Benchmarks** - Algorithm performance comparisons

---

**Previous Module:** [02-core-ml](../02-core-ml/) - Core ML Concepts
**Next Module:** [04-deep-learning](../04-deep-learning/) - Deep Learning
