# 04 - Deep Learning

## Overview

This module introduces neural networks and deep learning, the technology behind modern AI breakthroughs. You'll learn the foundations of neural networks, work with industry-standard frameworks (PyTorch and TensorFlow), master computer vision with CNNs, understand sequence modeling with RNNs, and explore transformer architectures that power large language models.

## Learning Path (Folder Order)

Follow this progressive deep learning curriculum:

1. **dl-foundations/** - Core neural network concepts and techniques
   - perceptron-and-mlp/ - Single neuron and multi-layer perceptrons
   - backpropagation/ - How neural networks learn through gradient flow
   - initialization-and-activations/ - Weight initialization and activation functions (ReLU, tanh, sigmoid)
   - optimization-sgd-adam/ - Optimizers: SGD, momentum, Adam, AdaGrad, RMSprop
   - regularization-dropout-batchnorm/ - Preventing overfitting in neural networks

2. **frameworks/** - Mastering deep learning frameworks
   - pytorch/ - PyTorch ecosystem (primary framework)
     - pytorch-basics/ - Tensors, modules, and basic operations
     - tensors-and-autograd/ - Automatic differentiation engine
     - datasets-and-dataloaders/ - Efficient data loading pipelines
     - training-loops/ - Custom training and validation loops
     - pytorch-model-export-deployment/ - Saving and deploying PyTorch models
   - tensorflow-keras/ - TensorFlow/Keras ecosystem
     - tf-keras-basics/ - High-level Keras API
     - tf-data-pipelines/ - TensorFlow data pipelines
     - custom-training-loops/ - Advanced TensorFlow training
     - tf-serving-and-tf-lite/ - Model serving and mobile deployment

3. **computer-vision/** - Deep learning for images
   - cnn-basics/ - Convolutional layers, pooling, and CNN architectures
   - modern-cnns-resnet-densenet/ - Advanced architectures: ResNet, DenseNet, EfficientNet
   - transfer-learning/ - Using pre-trained models for new tasks

4. **sequence-modeling/** - Deep learning for sequential data
   - rnn-lstm-gru/ - Recurrent networks and their variants
   - sequence-to-sequence/ - Encoder-decoder architectures
   - attention-for-sequences/ - Attention mechanisms for sequences

5. **transformers-and-llms/** - Modern transformer-based models
   - attention-basics/ - Self-attention and multi-head attention
   - transformer-architecture/ - Complete transformer model architecture
   - llm-overview/ - Large Language Models: BERT, GPT, T5, and beyond

## Resources

### üìö Books

- **"Deep Learning"** by Goodfellow, Bengio, Courville - The DL bible (free online)
- **"Hands-On Machine Learning"** by Aur√©lien G√©ron - Practical PyTorch and TensorFlow
- **"Deep Learning with PyTorch"** by Stevens, Antiga, Viehmann - Official PyTorch book
- **"Dive into Deep Learning"** (d2l.ai) - Interactive DL book (free online)
- **"Neural Networks and Deep Learning"** by Michael Nielsen - Free online, very clear
- **"Understanding Deep Learning"** by Simon Prince - Modern DL textbook (2023)
- **"Programming PyTorch for Deep Learning"** by Ian Pointer - Practical PyTorch guide

### üé• Videos

- **Fast.ai Practical Deep Learning for Coders** - Top-down DL approach
- **Stanford CS231n - CNN for Visual Recognition** - Classic computer vision course
- **Stanford CS224n - NLP with Deep Learning** - Transformers and language models
- **MIT 6.S191 Introduction to Deep Learning** - Comprehensive DL intro
- **Andrej Karpathy: Neural Networks Zero to Hero** - Build GPT from scratch
- **3Blue1Brown: Neural Networks Series** - Beautiful visual explanations
- **DeepLearning.AI TensorFlow Course** (Coursera) - Andrew Ng's TensorFlow course
- **PyTorch Official Tutorials** - YouTube channel with framework tutorials
- **Yannic Kilcher** - Paper reviews and explanations

### üéß Podcasts

- **Practical AI** - DL applications and industry trends
- **The TWIML AI Podcast** - Interviews with DL researchers
- **Gradient Dissent** - ML engineering and DL systems
- **Lex Fridman Podcast** - Deep conversations with AI pioneers (Hinton, LeCun, Bengio)
- **Machine Learning Street Talk** - Technical DL discussions
- **AI Alignment Podcast** - Safety and alignment in DL
- **The Robot Brains Podcast** - Robotics and deep reinforcement learning

### üìÑ Articles & Papers

**Foundational Papers:**
- **"ImageNet Classification with Deep CNNs"** (AlexNet, 2012) - Started the deep learning revolution
- **"Very Deep Convolutional Networks"** (VGG, 2014) - Deeper networks
- **"Deep Residual Learning"** (ResNet, 2015) - Skip connections enable very deep networks
- **"Attention Is All You Need"** (2017) - Original Transformer paper
- **"BERT: Pre-training of Deep Bidirectional Transformers"** (2018) - Bidirectional language models
- **"GPT-3: Language Models are Few-Shot Learners"** (2020) - Large language model scaling

**Learning Resources:**
- **Distill.pub** - Visual and interactive ML research articles
- **The Illustrated Transformer** by Jay Alammar - Best transformer visual guide
- **Understanding LSTM Networks** by Chris Olah - Clear RNN/LSTM explanation
- **Andrej Karpathy's Blog** - "The Unreasonable Effectiveness of RNNs" and more
- **PyTorch Tutorials** (pytorch.org/tutorials) - Official comprehensive guides
- **TensorFlow Tutorials** (tensorflow.org/tutorials) - Official TF learning resources

### üåê HTML/Interactive Resources

- **TensorFlow Playground** (playground.tensorflow.org) - Interactive neural network visualization
- **CNN Explainer** (poloclub.github.io/cnn-explainer) - Interactive CNN visualization
- **Transformer Explainer** - Interactive attention visualization
- **Netron** (netron.app) - Neural network visualizer
- **PyTorch Hub** - Pre-trained models repository
- **TensorFlow Hub** - Pre-trained model library
- **Hugging Face** (huggingface.co) - Transformers, datasets, and model hub
- **Papers with Code** (paperswithcode.com) - Papers with implementation code
- **Google Colab** - Free GPU/TPU notebooks
- **Kaggle Kernels** - Free GPU access with datasets
- **Gradient by Paperspace** - Cloud GPU notebooks

---

**Previous Module:** [03-classical-algorithms](../03-classical-algorithms/) - Classical ML Algorithms
**Next Module:** [05-special-topics](../05-special-topics/) - Special Topics and Applications
